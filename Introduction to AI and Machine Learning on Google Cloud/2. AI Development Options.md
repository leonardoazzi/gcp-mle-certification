- Pre-trained APIs
	- Pre-trained ML models
	- Também processa dados de áudio
	- Não precisa de dados e treinamento
- BigQuery ML
	- SQL queries para criar e executar modelos no BigQuery
	- Dados tabulares
	- Datasets médios-grandes
	- Tunar alguns hiperparâmetros
- AutoML
	- No-code para construir modelos no Vertex AI
	- Datasets pequenos-médios
- Custom training
	- Code yourself bro
	- Datasets médios-grandes
	- Tunar todos os hiperparâmetros

# Pre-trained APIs
E se tu não tem dados pra trabalhar? (engual eu)

- Speech, text and language
	- Natural Language
	- Speech to Text
	- Text to Speech
	- Translation
- Image and Video
	- Video
	- Vision intelligence
- Document and ata
	- Document
	- Document warehouse
- Conversational
	- Dialogflow

Várias bullshitagem de generative AI pra idiotas que nem o don usarem e se acharem muito foda.

# Vertex AI
- Endereça desafios de produção e facilidade de uso
- Plataforma para pipeline e2e de ML
- AutoML e custom training
- Agora é possível usar SQL no Workbench do Vertex AI

# AutoML
- Automatiza o processo de treinamento e deploy de modelos
- Auto data processing (Tensorflow Transform)
	- Automated Feature Engineering
- Architecture search and tuning
	- Neural architecture search
		- Procura modelos ótimos
		- Fazer o tuning automaticamente
	- Transfer learning
- Bagging ensemble
	- Por volta de 10 modelos selecionados
- Prediction

# Custom Training
- DIY
- Oferece containers pré-prontos, com os pacotes basicos
- Pode-se criar containers customizados
- Vertex AI Notebook
	- Jupyter Notebook
	- Colab Enterprise
		- Também pode ser usado 
- TensorFlow
	- hardware
	- apis baixo nível
		- ex. tensorflow-python
	- bibliotecas de modelos
		- ex. tf.layers, tf.metrics...
	- apis alto nível
		- ex tf.keras, tf.data...
- Keras
- JAX
	- High-performance library para computação numérica
	- Novas possibilidades para pesquisa e produção

# Lab
- API de NLP
- Análise de sentimento
- Features
	- Entities
		- Sujeitos no texto
	- Sentimentos
		- Emoção
	- Sintaxe
		- Informação linguística
	- Categorias
		- Categorização por palavras-chave
- Utilizar a API no código
	- Request Features from an input
		- analyzeEntities
		- analyzeSentiment
		- analyzeSyntax
		- classifText
	- request.json
	
```json 
{
	"document":{
	"type": "PLAIN_TEXT",
	"language": "PT-BR",
	"content": "puta que pariu meu gato pos um ovo"
	},
	"encodingType": "UTF8"
}
```

- Chamada analyzeEntities:
![[Pasted image 20240531163617.png]]

API Key: AIzaSyA08ROfWi-qKKTptgw_m3XR4DiVLv8xQbc

- The Natural Language API also supports sending files stored in Cloud Storage for text processing. If you wanted to send a file from Cloud Storage, you would replace `content` with `gcsContentUri` and give it a value of the text file's uri in Cloud Storage.